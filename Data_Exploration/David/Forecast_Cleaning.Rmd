---
title: "Cleaning the forecast_nsw dataset"
authors: "David Anderson z5343521"
date: "22/03/2022"
output: html_document
---

I wish to reduce the size of the forecast_nsw dataset so that we can store it on the GitHub repository.

```{r}
# Import libraries
library(lubridate)
#library(readr)
library(car)
library(ggplot2)
library(tidyverse)
library(dplyr)
library(data.table)
library(R.utils)
```


```{r}
# Import forecast dataset
fcst_nsw = fread("forecastdemand_nsw_reduced.csv.gz")
```


```{r}
## Import forecast dataset      
#setwd('../David/')
#getwd()

#t <- unz('forecastdemand_nsw_reduced.csv.zip', 'forecastdemand_nsw_reduced.csv')
#fcst_nsw <- read.csv(t, header = T)
```








Copied code from demand and temperature cleaning. Probably will need some common functions.

```{r}
# Get rid of columns that we don't require
temp_nsw <- temp_nsw[-c(1)]
dem_nsw <- dem_nsw[-c(3)]

# Split DATETIME into Date and Time columns
dem_nsw <- dem_nsw %>%
  mutate("Date" = str_extract(DATETIME, "[0-9]?[0-9]/[0-9]?[0-9]/[0-9]{4}"))
dem_nsw <- dem_nsw %>%
  mutate("Time" = str_extract(DATETIME, "[0-9]?[0-9]:[0-9]{2}"))
temp_nsw <- temp_nsw %>%
  mutate("Date" = str_extract(DATETIME, "[0-9]?[0-9]/[0-9]?[0-9]/[0-9]{4}"))
temp_nsw <- temp_nsw %>%
  mutate("Time" = str_extract(DATETIME, "[0-9]?[0-9]:[0-9]{2}"))

# Delete DATETIME columns
temp_nsw <- temp_nsw[-c(1)]
dem_nsw <- dem_nsw[-c(1)]

# Check for any missing values.
temp_nsw[rowSums(is.na(temp_nsw)) > 0, ] 
dem_nsw[rowSums(is.na(dem_nsw)) > 0, ]

```
No missing values?

Our data is from 01-01-2010 until 18-03-2021 which is 4094 days.

Check to see how many of each unique time value our dataframes contain.

```{r}
# Check the count of all unique time values in each data frame
as.data.frame(table(temp_nsw$Time))
as.data.frame(table(dem_nsw$Time))
```

This lines up with what we would expect in dem_nsw, if this follows the correct pattern of sampling every 30 mins across the span of our data we can use it as the data to left_join temp_nsw onto and resolve any issues from there.

We can also check that each date in the data contains 48 samples

```{r}
filter(as.data.frame(table(dem_nsw$Date)), Freq != 48)
```

This is as expected, the last date (18/3/2021) Was only sampled once.

```{r}
# Remove the last row to make this easier
dem_nsw <- dem_nsw[-196513, ]
```

So can we conclude from this that our data follows the time sampling format that we require?

Thus we have all of the times that we wish to include from 01-01-2010 until 18-03-2021, occurring in 30 minute intervals. 
We can do a left merge onto this data in order to preserve this structure and finish cleaning the temp data in this new structure.

```{r}
# Do a left merge on dem and temp data
NSW_df <- left_join(dem_nsw, temp_nsw, by = c('Date', 'Time'))
```

Why does this give extra rows?

```{r}
# Check where the extra rows have been inserted
filter(as.data.frame(table(NSW_df$Date)), Freq != 48)
```

The extra rows are all just identical, duplicated rows. Why did they appear though??

```{r}
# Get rid of duplicates
NSW_df <- NSW_df[!duplicated(NSW_df[, ]), ]
```

Our data is now in the correct time series format. We just need to make sure that the temperature data is all there and we can move on to visualization. Incorrectly entered data may still be an issue, this shoudl appear in visualization.

```{r}

# Check for NaN values
NSW_df[rowSums(is.na(NSW_df)) > 0, ]

```

Fill NaN values.

```{r}
# Replcae any NaN temperature data with the value before it. I would like this to be the average of the temperature before it and the one after it instead. Maybe re-write this later.
NSW_df <- NSW_df %>%
  mutate(TEMPERATURE = replace(TEMPERATURE, is.nan(TEMPERATURE), NA)) %>%
  fill(TEMPERATURE)
```

This concludes the data cleaning for now I think. More to come after visualization or as people proof this code, I'm sure.

```{r}
# Export the NSW_df to csv so that others can use it.
setwd('../report/')
write.csv(NSW_df, "Cleaned_Data.csv", row.names = FALSE)
```


```{r}

# Export the NSW_df to csv
#write.csv(fcst_nsw, file=gzfile("forecastdemand_nsw_reduced.csv.zip"), row.names = FALSE)
```





