# Remove PREDISPATCHSEQNO and REGIONID
# PREDISPATCHSEQNO is a descending series of numbers that correspond to forecasts taken over time, something like a primary key for each forecast conducted. The same information is still contained within the data if required.
# REGIONID is just 'NSW1'
fcst_nsw <- fcst_nsw[, -c(1,2)]
# Import forecast dataset. This will need to be changed to suit your own local directories
fcst_nsw <- read.csv('F:/Users/Dave/Desktop/forecastdemand_nsw.csv', header = T)
# Export the NSW_df to csv
write.csv(fcst_nsw, file = gzfile("./forecastdemand_nsw_reduced.csv.gz"), row.names = FALSE)
View(fcst_nsw)
# Export the NSW_df to csv
write.csv(fcst_nsw, file = gzfile("./forecastdemand_nsw_reduced.csv.gz"), row.names = FALSE)
View(fcst_nsw)
# Import forecast dataset. This will need to be changed to suit your own local directories
fcst_nsw <- read.csv('F:/Users/Dave/Desktop/forecastdemand_nsw.csv', header = T)
# Remove PREDISPATCHSEQNO and REGIONID
# PREDISPATCHSEQNO is a descending series of numbers that correspond to forecasts taken over time, something like a primary key for each forecast conducted. The same information is still contained within the data if required.
# REGIONID is just 'NSW1'
fcst_nsw <- fcst_nsw[, -c(1,2)]
# Export the NSW_df to csv
#write.csv(fcst_nsw, file = gzfile("./forecastdemand_nsw_reduced.csv.gz"), row.names = FALSE)
# Export the NSW_df to csv
write.csv(fcst_nsw, file = gzfile("./forecastdemand_nsw_reduced.csv.gz"), row.names = FALSE)
# Import libraries
library(lubridate)
library(car)
library(ggplot2)
library(tidyverse)
library(dplyr)
# Import temperature and demand datasets
temp_nsw <- read.csv(unz('temperature_nsw.csv.zip', 'temperature_nsw.csv'), header = T)
dem_nsw <- read.csv(unz('totaldemand_nsw.csv.zip', 'totaldemand_nsw.csv'), header = T)
# Get rid of columns that we don't require
temp_nsw <- temp_nsw[-c(1)]
dem_nsw <- dem_nsw[-c(3)]
# Split DATETIME into Date and Time columns
dem_nsw <- dem_nsw %>%
mutate("Date" = str_extract(DATETIME, "[0-9]?[0-9]/[0-9]?[0-9]/[0-9]{4}"))
dem_nsw <- dem_nsw %>%
mutate("Time" = str_extract(DATETIME, "[0-9]?[0-9]:[0-9]{2}"))
temp_nsw <- temp_nsw %>%
mutate("Date" = str_extract(DATETIME, "[0-9]?[0-9]/[0-9]?[0-9]/[0-9]{4}"))
temp_nsw <- temp_nsw %>%
mutate("Time" = str_extract(DATETIME, "[0-9]?[0-9]:[0-9]{2}"))
# Delete DATETIME columns
temp_nsw <- temp_nsw[-c(1)]
dem_nsw <- dem_nsw[-c(1)]
# Check for any missing values.
temp_nsw[rowSums(is.na(temp_nsw)) > 0, ]
dem_nsw[rowSums(is.na(dem_nsw)) > 0, ]
# Check the count of all unique time values in each data frame
as.data.frame(table(temp_nsw$Time))
as.data.frame(table(dem_nsw$Time))
filter(as.data.frame(table(dem_nsw$Date)), Freq != 48)
# Remove the last row to make this easier
dem_nsw <- dem_nsw[-196513, ]
# Check for duplicates
dem_nsw[duplicated(dem_nsw[, ]), ]
# Do a left merge on dem and temp data
cleaned_temp_dem_df <- left_join(dem_nsw, temp_nsw, by = c('Date', 'Time'))
# Check where the extra rows have been inserted
filter(as.data.frame(table(cleaned_temp_dem_df$Date)), Freq != 48)
# Get rid of duplicates
cleaned_temp_dem_df <- cleaned_temp_dem_df[!duplicated(cleaned_temp_dem_df[, ]), ]
# Check for NaN values
cleaned_temp_dem_df[rowSums(is.na(cleaned_temp_dem_df)) > 0, ]
# Replcae any NaN temperature data with the value before it. I would like this to be the average of the temperature before it and the one after it instead. Maybe re-write this later
cleaned_temp_dem_df <- cleaned_temp_dem_df %>%
mutate(TEMPERATURE = replace(TEMPERATURE, is.nan(TEMPERATURE), NA)) %>%
fill(TEMPERATURE)
# Convert date and time back to a datetime
cleaned_temp_dem_df$DATETIME <- paste(cleaned_temp_dem_df$Date, cleaned_temp_dem_df$Time)
cleaned_temp_dem_df$DATETIME <- dmy_hm(cleaned_temp_dem_df$DATETIME)
cleaned_temp_dem_df <- cleaned_temp_dem_df[, -c(2,3)]
# Export the cleaned_temp_dem_df to csv
write.csv(cleaned_temp_dem_df, "Cleaned_Data.csv", row.names = FALSE)
# Import libraries
library(lubridate)
library(dplyr)
library(data.table)
# Import forecast dataset
fcst_nsw = fread("forecastdemand_nsw_reduced.csv.gz")
# Create a new dataframe so that I can work on it and can re-load it from the original data without having to read the zipped file again which takes ages.
fcst_nsw2 <- fcst_nsw
# Convert the datetimes using lubridate
fcst_nsw2$LASTCHANGED <- ymd_hms(fcst_nsw2$LASTCHANGED)
fcst_nsw2$DATETIME <- ymd_hms(fcst_nsw2$DATETIME)
# Check to see how many forecasts there are from each model.
as.data.frame(table(fcst_nsw2$PERIODID))
# Make 32 different dataframes, each containing the data from forecast 1*30mins out to 32*30mins out
for (i in c(1,32)){
assign(paste0("Fcst", i), fcst_nsw2[fcst_nsw2$PERIODID == i, ][, -c(1, 3)])
}
#Import cleaned dataset
clean_NSW_data <- read.csv("Cleaned_Data.csv")
clean_NSW_data$DATETIME <- ymd_hms(clean_NSW_data$DATETIME)
# Rename the forecast demand columns to something more appropriate for each forecast
Fcst1 <- rename(Fcst1, Fcst1 = FORECASTDEMAND)
Fcst32 <- rename(Fcst32, Fcst32 = FORECASTDEMAND)
# Do a left merge on clean_NSW_data and the forecast1 and forecast31 data
clean_data_w_fcst <- left_join(clean_NSW_data, Fcst1, by = 'DATETIME', copy = TRUE)
clean_data_w_fcst <- left_join(clean_data_w_fcst, Fcst32, by = 'DATETIME', copy = TRUE)
# Create a column containing how much this forecast was away from the actual consumption
clean_data_w_fcst$Fcst1_res <- clean_data_w_fcst$TOTALDEMAND - clean_data_w_fcst$Fcst1
clean_data_w_fcst$Fcst32_res <- clean_data_w_fcst$TOTALDEMAND - clean_data_w_fcst$Fcst32
# Fill NA values with the value before it.
setnafill(clean_data_w_fcst, type = "locf")
# Plot this difference
boxplot(clean_data_w_fcst$Fcst1_res, clean_data_w_fcst$Fcst32_res)
library(metrics)
install.packages("Metrics")
# Make 32 different dataframes, each containing the data from forecast 1*30mins out to 32*30mins out
for (i in c(1,32)){
assign(paste0("Fcst", i), fcst_nsw2[fcst_nsw2$PERIODID == i, ][, -c(1, 3)])
}
#Import cleaned dataset
clean_NSW_data <- read.csv("Cleaned_Data.csv")
clean_NSW_data$DATETIME <- ymd_hms(clean_NSW_data$DATETIME)
# Rename the forecast demand columns to something more appropriate for each forecast
Fcst1 <- rename(Fcst1, Fcst1 = FORECASTDEMAND)
Fcst32 <- rename(Fcst32, Fcst32 = FORECASTDEMAND)
# Do a left merge on clean_NSW_data and the forecast1 and forecast31 data
clean_data_w_fcst <- left_join(clean_NSW_data, Fcst1, by = 'DATETIME', copy = TRUE)
clean_data_w_fcst <- left_join(clean_data_w_fcst, Fcst32, by = 'DATETIME', copy = TRUE)
# Create a column containing how much this forecast was away from the actual consumption
clean_data_w_fcst$Fcst1_res <- clean_data_w_fcst$TOTALDEMAND - clean_data_w_fcst$Fcst1
clean_data_w_fcst$Fcst32_res <- clean_data_w_fcst$TOTALDEMAND - clean_data_w_fcst$Fcst32
# Fill NA values with the value before it.
setnafill(clean_data_w_fcst, type = "locf")
# Plot this difference
boxplot(clean_data_w_fcst$Fcst1_res, clean_data_w_fcst$Fcst32_res)
library(Metrics)
# Caluculate five number summaries
mae(clean_data_w_fcst$TOTALDEMAND, clean_data_w_fcst$Fcst1)
mae(clean_data_w_fcst$TOTALDEMAND, clean_data_w_fcst$Fcst2)
View(clean_data_w_fcst)
# Make 32 different dataframes, each containing the data from forecast 1*30mins out to 32*30mins out
for (i in c(1,32)){
assign(paste0("Fcst", i), fcst_nsw2[fcst_nsw2$PERIODID == i, ][, -c(1, 3)])
}
#Import cleaned dataset
clean_NSW_data <- read.csv("Cleaned_Data.csv")
clean_NSW_data$DATETIME <- ymd_hms(clean_NSW_data$DATETIME)
# Rename the forecast demand columns to something more appropriate for each forecast
Fcst1 <- rename(Fcst1, Fcst1 = FORECASTDEMAND)
Fcst32 <- rename(Fcst32, Fcst32 = FORECASTDEMAND)
# Do a left merge on clean_NSW_data and the forecast1 and forecast31 data
clean_data_w_fcst <- left_join(clean_NSW_data, Fcst1, by = 'DATETIME', copy = TRUE)
clean_data_w_fcst <- left_join(clean_data_w_fcst, Fcst32, by = 'DATETIME', copy = TRUE)
# Create a column containing how much this forecast was away from the actual consumption
clean_data_w_fcst$Fcst1_res <- clean_data_w_fcst$TOTALDEMAND - clean_data_w_fcst$Fcst1
clean_data_w_fcst$Fcst32_res <- clean_data_w_fcst$TOTALDEMAND - clean_data_w_fcst$Fcst32
# Fill NA values with the value before it.
setnafill(clean_data_w_fcst, type = "locf")
# Plot this difference
boxplot(clean_data_w_fcst$Fcst1_res, clean_data_w_fcst$Fcst32_res)
library(Metrics)
# Caluculate five number summaries
mae(clean_data_w_fcst$TOTALDEMAND, clean_data_w_fcst$Fcst1)
mae(clean_data_w_fcst$TOTALDEMAND, clean_data_w_fcst$Fcst32)
# Export the clean_data_w_fcst to csv
write.csv(clean_data_w_fcst, "Cleaned_Data_w_fcst.csv", row.names = FALSE)
# Import libraries
library(lubridate)
library(ggplot2)
library(dplyr)
library(hms)
library(Metrics)
library(corrplot)
# Import cleaned data
Clean_df <- read.csv("Cleaned_Data.csv")
Clean_df$DATETIME <- ymd_hms(Clean_df$DATETIME)
# Plot the temp and demand data per year
ggplot(Clean_df, aes(x = TEMPERATURE, y = TOTALDEMAND)) +
ggtitle("Temperature vs Demand for 2010-2021") +
xlab('Temperature (deg celcius)') +
ylab('Demand (MW)') +
geom_point()
# Boxplot demand vs time of day
ggplot(Clean_df, aes(x = as_hms(DATETIME), y = TOTALDEMAND, group = as_hms(DATETIME))) +
ggtitle("Demand vs Time of Day") +
xlab('Time') +
ylab('Demand (MW)') +
geom_boxplot()
# Boxplot demand over day of the week
ggplot(Clean_df, aes(x = wday(DATETIME), y = TOTALDEMAND, group = wday(DATETIME))) +
ggtitle("Demand vs Day of Week") +
xlab('Day of Week') +
ylab('Demand (MW)') +
geom_boxplot()
# Boxplotdemand vs week of the year
ggplot(Clean_df, aes(x = week(DATETIME), y = TOTALDEMAND, group = week(DATETIME))) +
ggtitle("Demand vs Week of Year") +
xlab('Week of Year') +
ylab('Demand (MW)') +
geom_boxplot()
# Boxplot demand vs month of year
ggplot(Clean_df, aes(x = month(DATETIME), y = TOTALDEMAND, group = month(DATETIME))) +
ggtitle("Demand vs Month of Year") +
xlab('Month of Year') +
ylab('Demand (MW)') +
geom_boxplot()
# Convert column names to something nicer
Clean_df$Demand <- Clean_df$TOTALDEMAND
Clean_df$Temperature <- Clean_df$TEMPERATURE
Clean_df$Day <- wday(Clean_df$DATETIME)
Clean_df$Month <- month(Clean_df$DATETIME)
Clean_df$Time <- as_hms(Clean_df$DATETIME)
Clean_df <- Clean_df[, -c(1,2,3)]
# Convert time to numeric
Clean_df$Time <- (hour(Clean_df$Time)*60 + minute(Clean_df$Time))/30
# Plot corrplot
M <- cor(Clean_df)
corrplot(M, method = "number")
