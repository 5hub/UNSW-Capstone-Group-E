{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to explore Random Forest Regressors and Support Vector Machines along with some input variables to see if we can make a model that accurately forecasts energy demand. We aim to achieve better results than simply saying 'The demand in 30 minutes time will be the same as it is right now'. This is calculated below as having a mean average loss of 218."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "221"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Suppress annoying deprecation warnings\n",
    "from warnings import filterwarnings  # noqa\n",
    "filterwarnings(action='ignore',\n",
    "                        category=DeprecationWarning,\n",
    "                        module='sklearn')  # noqa\n",
    "\n",
    "# Import libraries\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import make_scorer\n",
    "from datetime import datetime, timedelta\n",
    "import forestci as fci\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set path to current directory\n",
    "sys.path.append(os.path.abspath(os.getcwd()))\n",
    "\n",
    "# read data\n",
    "data = pd.read_csv('./Cleaned_Data_mkII.csv')\n",
    "\n",
    "# Set random state\n",
    "STATE = 69\n",
    "\n",
    "# If set to true, models will perform hyperparameter tuning. If false they will use\n",
    "# pre-defined values\n",
    "SEARCH = False\n",
    "\n",
    "# Makes sure datetime is in datetime format\n",
    "data['DATETIME'] = pd.to_datetime(data['DATETIME'])\n",
    "\n",
    "# We want to test a time column as an input\n",
    "data['time'] = (data['DATETIME'].dt.strftime(\"%H%M%S\"))\n",
    "\n",
    "# Also would like to test demand and tmeperature 30, 60 and 90 mins before the current time as input\n",
    "# These were found to have diminishing return after 60 mins out for demand and 30 mins out for temp\n",
    "data['demand_30'] = data.TOTALDEMAND.shift(1)\n",
    "data['demand_60'] = data.TOTALDEMAND.shift(2)\n",
    "data['demand_90'] = data.TOTALDEMAND.shift(3)\n",
    "\n",
    "data['temp_30'] = data.TEMPERATURE.shift(1)\n",
    "data['temp_60'] = data.TEMPERATURE.shift(2)\n",
    "data['temp_90'] = data.TEMPERATURE.shift(3)\n",
    "\n",
    "######### Change the number of years\n",
    "# Select only data from the past 1 years to make hyperparameter tuning take less time\n",
    "mask = (data['DATETIME'] >= '2020-03-16') & (data['DATETIME'] < '2021-03-16')\n",
    "data = data.loc[mask]\n",
    "\n",
    "# The loss that we aim to beat\n",
    "#round(math.sqrt(mean_squared_error(data['TOTALDEMAND'], data['demand_30'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will try a random forrest regressor with just demand and temperature data for a benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features and target sets\n",
    "base_features = data[['time', 'temp_30', 'demand_30', 'demand_60']]\n",
    "base_target = data['TOTALDEMAND']\n",
    "\n",
    "# Convert to numpy arrays and split training/test data\n",
    "base_features_np = pd.DataFrame(base_features).to_numpy()\n",
    "base_target_np = np.ravel(pd.DataFrame(base_target).to_numpy())\n",
    "\n",
    "base_features_train, base_features_test, base_target_train, base_target_test = train_test_split(base_features_np,\n",
    "                                                                            base_target_np, random_state = STATE)\n",
    "\n",
    "# Implement Random Forest\n",
    "base_rnd_clf = RandomForestRegressor(random_state = STATE)\n",
    "base_rnd_clf.fit(base_features_train, base_target_train)\n",
    "\n",
    "# Print error\n",
    "base_rf_predicted = base_rnd_clf.predict(base_features_test)\n",
    "base_rf_error = round(math.sqrt(mean_squared_error(base_target_test, base_rf_predicted)))\n",
    "#print(\"Baseline Random Forest Error: \", base_rf_error)\n",
    "\n",
    "# Look at parameters used by our current forest\n",
    "#print('Parameters currently in use:\\n')\n",
    "#pprint(base_rnd_clf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, try to include an indicator of if it is a weekday or not, and weather data to see if these increase performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['RAIN_NONE', 'RAIN_LIGHT', 'RAIN_MODERATE', 'RAIN_HEAVY'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_12776/1904295922.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[1;31m# Create features and target sets\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 28\u001B[1;33m features = data[['time', 'temp_30', 'demand_30', 'demand_60', \n\u001B[0m\u001B[0;32m     29\u001B[0m                  'RAIN_NONE','RAIN_LIGHT','RAIN_MODERATE','RAIN_HEAVY', 'is_weekday']]\n\u001B[0;32m     30\u001B[0m \u001B[0mtarget\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'TOTALDEMAND'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3462\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mis_iterator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3463\u001B[0m                 \u001B[0mkey\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3464\u001B[1;33m             \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_listlike_indexer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3465\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3466\u001B[0m         \u001B[1;31m# take() does not accept boolean indexers\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m_get_listlike_indexer\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1312\u001B[0m             \u001B[0mkeyarr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindexer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnew_indexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0max\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reindex_non_unique\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkeyarr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1313\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1314\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_validate_read_indexer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkeyarr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindexer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1315\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1316\u001B[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m_validate_read_indexer\u001B[1;34m(self, key, indexer, axis)\u001B[0m\n\u001B[0;32m   1375\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1376\u001B[0m             \u001B[0mnot_found\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mensure_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mmissing_mask\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnonzero\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munique\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1377\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"{not_found} not in index\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1378\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1379\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: \"['RAIN_NONE', 'RAIN_LIGHT', 'RAIN_MODERATE', 'RAIN_HEAVY'] not in index\""
     ]
    }
   ],
   "source": [
    "# And an indictor if it is a weekend or not\n",
    "data['is_weekday'] = data['DATETIME'].dt.weekday\n",
    "data['is_weekday'] = np.where(data['is_weekday'] < 5, 1, 0)\n",
    "\n",
    "# import weather data\n",
    "weather = pd.read_csv('weather.csv')\n",
    "\n",
    "# Convert datetime to date\n",
    "weather['DATE'] = pd.to_datetime(weather[['Year','Month','Day']]).dt.date\n",
    "\n",
    "# Extract just day and rain columns\n",
    "weather.columns = ['drop1','drop2','drop3','drop4','drop5','rain','drop6','drop7','DAY']\n",
    "weather = weather[['DAY','rain']]\n",
    "\n",
    "# Fill NA values\n",
    "weather['rain'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Create dummy variables for rain for better model use\n",
    "weather['RAIN'] = pd.cut(weather['rain'],bins=[-1,0.2,4,10,999999],labels=['NONE','LIGHT','MODERATE','HEAVY'])\n",
    "weather_dummy = pd.get_dummies(weather,columns=['RAIN'])\n",
    "\n",
    "# Create day column in data and merge using it\n",
    "data['DAY'] = data['DATETIME'].dt.date\n",
    "\n",
    "data = data.merge(weather_dummy, on='DAY')\n",
    "\n",
    "# Create features and target sets\n",
    "features = data[['time', 'temp_30', 'demand_30', 'demand_60', \n",
    "                 'RAIN_NONE','RAIN_LIGHT','RAIN_MODERATE','RAIN_HEAVY', 'is_weekday']]\n",
    "target = data['TOTALDEMAND']\n",
    "\n",
    "# Convert to numpy arrays and split training/test data\n",
    "features_np = pd.DataFrame(features).to_numpy()\n",
    "target_np = np.ravel(pd.DataFrame(target).to_numpy())\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features_np, target_np, random_state = STATE)\n",
    "\n",
    "# Implement Random Forest\n",
    "rnd_clf = RandomForestRegressor(random_state = STATE)\n",
    "rnd_clf.fit(features_train, target_train)\n",
    "\n",
    "# Print error\n",
    "rf_predicted = rnd_clf.predict(features_test)\n",
    "rf_error = round(math.sqrt(mean_squared_error(target_test, rf_predicted)))\n",
    "\n",
    "# Look at parameters used by our current forest\n",
    "#print('Parameters currently in use:\\n')\n",
    "#pprint(rnd_clf.get_params())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weekday and weather data aren't contributing to the basline model. Try random search of optimizing hyperparamters as a quick way to tell if our baseline model can perform any better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune hyperparameters\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': list(range(2, 20, 2)),\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'max_depth': list(range(1, 20, 1)),\n",
    "               'min_samples_split': list(range(2, 10, 1)),\n",
    "               'min_samples_leaf': list(range(2, 10, 1)),\n",
    "               'bootstrap': [True, False]}\n",
    "\n",
    "# Random parameter search (3 fold CV)\n",
    "\n",
    "if SEARCH:\n",
    "    rf_random = RandomizedSearchCV(estimator = RandomForestRegressor, param_distributions = random_grid,\n",
    "                                n_iter = 10, cv = 5, verbose = 2, random_state = STATE, n_jobs = -1)\n",
    "    rf_random.fit(features_train, target_train)\n",
    "    best_random_pred = rf_random.best_estimator_.predict(base_features_test)\n",
    "    best_random_error = round(math.sqrt(mean_squared_error(base_target_test,best_random_pred)))\n",
    "else:\n",
    "    rf_random = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=19,\n",
    "                                      max_features='sqrt', max_leaf_nodes=None,\n",
    "                                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                      min_samples_leaf=7, min_samples_split=5,\n",
    "                                      min_weight_fraction_leaf=0.0, n_estimators=18, n_jobs=None,\n",
    "                                      oob_score=False, random_state=STATE, verbose=0, warm_start=False)\n",
    "    rf_random.fit(base_features_train, base_target_train)\n",
    "    best_random_pred = rf_random.predict(base_features_test)\n",
    "    best_random_error = round(math.sqrt(mean_squared_error(base_target_test,best_random_pred)))\n",
    "\n",
    "# Print error\n",
    "#print(\"Randomized Hyp Tuning Error: \", best_random_error)\n",
    "\n",
    "# Look at parameters used\n",
    "#print('Parameters currently in use:\\n')\n",
    "#pprint(rf_random.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tuning is only trivially better than our base model. No point in continuing hyperparpmeter tuning further, or in continuing with the model, unless we can think of other inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now start with SVM modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Support Vector Machine Regressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "regressor = SVR(kernel = 'rbf')\n",
    "regressor.fit(base_features_train, base_target_train)\n",
    "\n",
    "svm_predicted = regressor.predict(base_features_test)\n",
    "svm_error = round(math.sqrt(mean_squared_error(base_target_test, svm_predicted)))\n",
    "\n",
    "#print(\"SVM Error: \", svm_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_param_grid = {'C' : [0.1, 1, 10, 100, 1000],\n",
    "                 'gamma' : [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "                 'kernel' : ['rbf']}\n",
    "\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "if SEARCH:\n",
    "    svr_gs = GridSearchCV(SVR(), SVM_param_grid, scoring=scorer, random_state=STATE)\n",
    "else:\n",
    "    svr_gs = SVR(C=1000, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.0001,\n",
    "                 kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "\n",
    "svr_gs.fit(base_features_train, base_target_train)\n",
    "\n",
    "grid_preds = svr_gs.predict(base_features_test)\n",
    "best_SVM_grid_error = round(math.sqrt(mean_squared_error(base_target_test, grid_preds)))\n",
    "\n",
    "# Print error\n",
    "#print(\"SVM Grid Search Tuning Error: \", best_SVM_grid_error)\n",
    "\n",
    "# Look at parameters used\n",
    "#print('Parameters currently in use:\\n')\n",
    "#pprint(svr_gs.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL SCORES\n",
      "Untuned Random Forest Error:  89\n",
      "Tuned Random Forest Error:  93\n",
      "Untuned SVM Error:  1056\n",
      "Tuned SVM Error:  457\n",
      "Benchmark Error:  221\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE for each model and benchmark\n",
    "# Lower = better model\n",
    "\n",
    "rf_error = round(math.sqrt(mean_squared_error(target_test, rf_predicted)))\n",
    "svm_error = round(math.sqrt(mean_squared_error(target_test, svm_predicted)))\n",
    "benchmark_error = round(math.sqrt(mean_squared_error(data['TOTALDEMAND'], data['demand_30'])))\n",
    "\n",
    "print(\"FINAL SCORES\")\n",
    "print(\"Untuned Random Forest Error: \", rf_error)\n",
    "print(\"Tuned Random Forest Error: \", best_random_error)\n",
    "print(\"Untuned SVM Error: \", svm_error)\n",
    "print(\"Tuned SVM Error: \", best_SVM_grid_error)\n",
    "print(\"Benchmark Error: \", benchmark_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "\n",
    "predictions = list(rf_random.predict(base_features_np))\n",
    "targets = list(base_target_np)\n",
    "output = pd.DataFrame({'prediction':predictions,'target':targets})\n",
    "output.to_csv('output_rf.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}