{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "# Set path to current directory\n",
    "sys.path.append(os.path.abspath(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Load data and split target and features\n",
    "\n",
    "# Set this to the percentage of the full data file we want to use. Smaller percentages will reduce computation time for testing\n",
    "PROPORTION = .1\n",
    "#Random state for repeatable runs\n",
    "STATE = 42\n",
    "\n",
    "data = pd.read_csv('./full_data.csv', index_col=0)\n",
    "data = data[data['STATE'] == 'NSW'] # We are only looking at NSW here\n",
    "data = data.sample(frac = PROPORTION)\n",
    "\n",
    "features = data.iloc[:, 1 : -1 ]\n",
    "target = data.iloc[:,  -1 ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Dummy coding for states\n",
    "# Not needed because states not used\n",
    "\n",
    "#features = pd.get_dummies(features,columns=['STATE'])\n",
    "features = features[['TEMPERATURE']]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Convert to numpy arrays and split training/test data\n",
    "\n",
    "features_np = pd.DataFrame(features).to_numpy()\n",
    "target_np = np.ravel(pd.DataFrame(target).to_numpy())\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features_np, target_np, random_state= STATE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=15.0min\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 2.2min\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=1200; total time=12.6min\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=19.1min\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=1800; total time=18.9min\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time= 5.6min\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=27.4min\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time= 5.7min\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1600; total time=24.0min\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time= 8.6min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1400; total time=14.5min\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=1800; total time=18.8min\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=13.6min\n",
      "[CV] END bootstrap=False, max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1200; total time=16.6min\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 2.8min\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time= 5.6min\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time= 5.2min\n"
     ]
    }
   ],
   "source": [
    "# Implement Random Forest\n",
    "# TODO: Make it better\n",
    "\n",
    "#Hyperparameter tuning grid\n",
    "random_grid = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)],\n",
    "               'max_features': ['auto','sqrt'],\n",
    "               'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'bootstrap': [True, False]}\n",
    "\n",
    "rnd_clf = RandomForestRegressor(random_state = STATE)\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rnd_clf, param_distributions = random_grid, n_iter = 25, cv = 3, verbose=2, random_state=STATE, n_jobs = -1)# Fit the random search model\n",
    "rf_random.fit(features_train, target_train)\n",
    "\n",
    "rf_predicted = rf_random.predict(features_test)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Implement Support Vector Machine Regressor\n",
    "# TODO: Make it better\n",
    "\n",
    "svm_reg = LinearSVR(epsilon=1.5)\n",
    "svm_reg.fit(features_train, target_train)\n",
    "svm_predicted = svm_reg.predict(features_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Error:  1201\n",
      "SVM Error:  1304\n",
      "Benchmark Error:  790\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE for each model and benchmark\n",
    "# Lower = better model\n",
    "\n",
    "rf_error = round(math.sqrt(mean_squared_error(target_test, rf_predicted)))\n",
    "svm_error = round(math.sqrt(mean_squared_error(target_test, svm_predicted)))\n",
    "benchmark_error = round(math.sqrt(mean_squared_error(data['TOTALDEMAND'], data['FORECASTDEMAND'])))\n",
    "\n",
    "print(\"Random Forest Error: \", rf_error)\n",
    "print(\"SVM Error: \", svm_error)\n",
    "print(\"Benchmark Error: \", benchmark_error)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}